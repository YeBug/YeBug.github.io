---
title: 部署优化策略
date: 2023-07-13 16:14:32 +/-0800
categories: [learning, project]
tags: [deep learning]     # TAG names should always be lowercase
---

## 背景
基于ROS与Triton搭建的流式推理服务平台，部署模型后执行终端可视化，发现多模型并行推理可视化耗时高，继而优化之。

## 优化策略
### 优化对象
模型流水线：`preprocess-->inference-->postprocess` 
多模型并行：三个图像算法，一个点云算法

### 耗时分析
多模型并行调用，可使用`perf_analyzer`在Triton上模拟调用，并行调用流水线后观察CPU占用率高，GPU空闲。 
原因：预处理模块带有大量矩阵计算与图像处理操作，均为CPU计算，numpy和opencv方法的调用成为一个瓶颈。

### 优化方案
将CPU计算任务分发到GPU上执行，矩阵计算GPU加速，图像处理GPU加速。 
1. 可用tensor替代的numpy操作则转换为tensor，加载到GPU上计算。 
2. 将opencv库替换为可在GPU上执行的图像处理库，例如Nvidia VPI，DALI，CV-CUDA等。本次优化使用[VPI](https://docs.nvidia.com/vpi/algorithms.html)执行替换。 
3. 点云转体素，调用稀疏卷积spconv库，单帧点云数据量在十万行量级，耗时较高。使用基于CUDA的计算方案，将原有的Point2VoxelCPU类替换为PointToVoxel类，类内的计算过程采用torch.tensor的数据结构，放在GPU上执行。
4. 计算任务中，可视具体情况将numpy的opt替换为cupy，需注意的是cupy数据加载到cpu上的过程较耗时，需要权衡计算耗时与H2D&D2H的耗时。